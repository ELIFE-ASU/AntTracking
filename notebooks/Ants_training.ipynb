{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 28\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "type_labels = {'individual': [1, 0, 0], 'tandem': [0, 1, 0], 'transport': [0, 0, 1]}\n",
    "\n",
    "for img_type in type_labels:\n",
    "    path = os.path.join('../data/ant_img_gs/', img_type)\n",
    "    for img_file in os.listdir(path):\n",
    "        if not img_file.startswith('.') and img_file.endswith('.png'):\n",
    "            im = cv2.imread(os.path.join(path, img_file), 0)\n",
    "            if im.shape != (SIZE, SIZE):\n",
    "                continue\n",
    "            # Normalize\n",
    "            mask = im != 0\n",
    "            im = mask * (im / 256.)\n",
    "            \n",
    "            images.append(im)\n",
    "            labels.append(type_labels[img_type])\n",
    "        \n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20718, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(images))\n",
    "shuffled_images = images[perm]\n",
    "shuffled_labels = labels[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = len(images) * 9 // 10\n",
    "\n",
    "training_images = shuffled_images[:training_size]\n",
    "training_labels = shuffled_labels[:training_size]\n",
    "\n",
    "test_images = shuffled_images[training_size:]\n",
    "test_labels = shuffled_labels[training_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NN with 1 hidden layer.\n",
    "x = tf.placeholder(tf.float32, shape=[None, SIZE*SIZE])\n",
    "W1 = tf.Variable(tf.truncated_normal([900, 100], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([100]))\n",
    "z1 = tf.nn.softmax(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([100, 3], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "y = tf.matmul(z1, W2) + b2\n",
    "\n",
    "y_ = tf.placeholder(tf.int32, shape=[None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "x = tf.placeholder(tf.float32, shape=[None, SIZE, SIZE])\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, SIZE, SIZE, 1])\n",
    "    \n",
    "with tf.name_scope('conv'):\n",
    "    W_conv = weight_variable([3, 3, 1, 8])\n",
    "    b_conv = bias_variable([8])\n",
    "    h_conv = tf.nn.relu(tf.nn.conv2d(x_image, W_conv, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    \n",
    "with tf.name_scope('pool'):\n",
    "    h_pool = tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "with tf.name_scope('fc1'):\n",
    "    W_fc1 = weight_variable([SIZE//2*SIZE//2*8, 100])\n",
    "    b_fc1 = bias_variable([100])\n",
    "        \n",
    "    h_pool_flat = tf.reshape(h_pool, [-1, SIZE//2*SIZE//2*8])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "with tf.name_scope('fc2'):\n",
    "    W_fc2 = weight_variable([100, 3])\n",
    "    b_fc2 = bias_variable([3])\n",
    "\n",
    "    y = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/5000 Training accuracy 0.6598734259605408. 31 s\n",
      "200/5000 Training accuracy 0.7272337079048157. 25 s\n",
      "300/5000 Training accuracy 0.7709964513778687. 24 s\n",
      "400/5000 Training accuracy 0.7757159471511841. 24 s\n",
      "500/5000 Training accuracy 0.7846186757087708. 24 s\n",
      "600/5000 Training accuracy 0.7971146702766418. 24 s\n",
      "700/5000 Training accuracy 0.8129357695579529. 24 s\n",
      "800/5000 Training accuracy 0.8257535099983215. 24 s\n",
      "900/5000 Training accuracy 0.8410382866859436. 25 s\n",
      "1000/5000 Training accuracy 0.8570739030838013. 24 s\n",
      "1100/5000 Training accuracy 0.8668347001075745. 24 s\n",
      "1200/5000 Training accuracy 0.8740212321281433. 25 s\n",
      "1300/5000 Training accuracy 0.8799742460250854. 24 s\n",
      "1400/5000 Training accuracy 0.8861417770385742. 24 s\n",
      "1500/5000 Training accuracy 0.8899495601654053. 25 s\n",
      "1600/5000 Training accuracy 0.8937037587165833. 24 s\n",
      "1700/5000 Training accuracy 0.8967607021331787. 24 s\n",
      "1800/5000 Training accuracy 0.900407612323761. 24 s\n",
      "1900/5000 Training accuracy 0.9029818773269653. 25 s\n",
      "2000/5000 Training accuracy 0.9063606262207031. 25 s\n",
      "2100/5000 Training accuracy 0.9111337661743164. 24 s\n",
      "2200/5000 Training accuracy 0.9132253527641296. 24 s\n",
      "2300/5000 Training accuracy 0.9167649745941162. 25 s\n",
      "2400/5000 Training accuracy 0.9189638495445251. 25 s\n",
      "2500/5000 Training accuracy 0.9209482073783875. 25 s\n",
      "2600/5000 Training accuracy 0.9229861497879028. 25 s\n",
      "2700/5000 Training accuracy 0.9250777363777161. 25 s\n",
      "2800/5000 Training accuracy 0.9269012212753296. 25 s\n",
      "2900/5000 Training accuracy 0.9296900033950806. 25 s\n",
      "3000/5000 Training accuracy 0.9308698773384094. 25 s\n",
      "3100/5000 Training accuracy 0.9323179125785828. 25 s\n",
      "3200/5000 Training accuracy 0.9346776604652405. 25 s\n",
      "3300/5000 Training accuracy 0.9363402128219604. 25 s\n",
      "3400/5000 Training accuracy 0.9389681220054626. 25 s\n",
      "3500/5000 Training accuracy 0.9405770897865295. 25 s\n",
      "3600/5000 Training accuracy 0.942078709602356. 25 s\n",
      "3700/5000 Training accuracy 0.9429368376731873. 25 s\n",
      "3800/5000 Training accuracy 0.9451892971992493. 25 s\n",
      "3900/5000 Training accuracy 0.9470663666725159. 25 s\n",
      "4000/5000 Training accuracy 0.9481926560401917. 25 s\n",
      "4100/5000 Training accuracy 0.9492652416229248. 25 s\n",
      "4200/5000 Training accuracy 0.9509814381599426. 25 s\n",
      "4300/5000 Training accuracy 0.9525903463363647. 25 s\n",
      "4400/5000 Training accuracy 0.9536629915237427. 25 s\n",
      "4500/5000 Training accuracy 0.9547892212867737. 25 s\n",
      "4600/5000 Training accuracy 0.9553255438804626. 25 s\n",
      "4700/5000 Training accuracy 0.9571489691734314. 25 s\n",
      "4800/5000 Training accuracy 0.9580606818199158. 25 s\n",
      "4900/5000 Training accuracy 0.9594014883041382. 25 s\n",
      "5000/5000 Training accuracy 0.9602059125900269. 25 s\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "start_time = time.time()\n",
    "steps = 5000\n",
    "for i in range(steps):\n",
    "    if (i+1) % 100 == 0:\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        delta_time = time.time() - start_time\n",
    "        time_message = '{} s'.format(int(delta_time)) if delta_time > 1 else '{} ms'.format(int(delta_time * 1000))\n",
    "        \n",
    "        print('{}/{} Training accuracy {}. {}'.format(i+1, steps, sess.run(accuracy, feed_dict={x: training_images, y_: training_labels}),\n",
    "                                                time_message))\n",
    "        start_time = time.time()\n",
    "        \n",
    "        saver.save(sess, '../data/tf_save/trained_model.ckpt')\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x: training_images, y_: training_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.921332061290741\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy {}'.format(sess.run(accuracy, feed_dict={x: test_images, y_:test_labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Session Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_save/trained_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver.restore(sess, 'tf_save/trained_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1203c12b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1202e3ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('test_patches/ants.png', 0)\n",
    "plt.imshow(img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.argmax(y, 1), feed_dict={x: [img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
