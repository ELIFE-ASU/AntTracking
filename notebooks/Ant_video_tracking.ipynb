{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XMIN = 1470\n",
    "XMAX = 2840\n",
    "YMIN = 50\n",
    "YMAX = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_centroids(th, min_size):\n",
    "    if min_size < 1:\n",
    "        raise ValueError('min_size must be at least 1')\n",
    "    \n",
    "    _, cont, _ = cv2.findContours(th, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    M = map(cv2.moments, cont)\n",
    "    \n",
    "    cxs = []\n",
    "    cys = []\n",
    "\n",
    "    for i, m in enumerate(M):\n",
    "        if m['m00'] < min_size:\n",
    "            continue\n",
    "\n",
    "        cx = int(m['m10']/m['m00'])\n",
    "        cy = int(m['m01']/m['m00'])\n",
    "\n",
    "        cxs.append(cx)\n",
    "        cys.append(cy)\n",
    "      \n",
    "    return cxs, cys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_masked_window(grayed, cx, cy, size):\n",
    "    windowed = grayed[cy-size//2:cy+size//2, cx-size//2:cx+size//2]\n",
    "    _, bw = cv2.threshold(windowed, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    _, cont, _ = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    if 0 < len(cont) < 3:\n",
    "        return windowed * (bw == 0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../data/tf_save/trained_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# CNN\n",
    "SIZE = 28\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, SIZE, SIZE])\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, SIZE, SIZE, 1])\n",
    "    \n",
    "with tf.name_scope('conv'):\n",
    "    W_conv = weight_variable([3, 3, 1, 8])\n",
    "    b_conv = bias_variable([8])\n",
    "    h_conv = tf.nn.relu(tf.nn.conv2d(x_image, W_conv, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    \n",
    "with tf.name_scope('pool'):\n",
    "    h_pool = tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "with tf.name_scope('fc1'):\n",
    "    W_fc1 = weight_variable([SIZE//2*SIZE//2*8, 100])\n",
    "    b_fc1 = bias_variable([100])\n",
    "        \n",
    "    h_pool_flat = tf.reshape(h_pool, [-1, SIZE//2*SIZE//2*8])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "with tf.name_scope('fc2'):\n",
    "    W_fc2 = weight_variable([100, 3])\n",
    "    b_fc2 = bias_variable([3])\n",
    "\n",
    "    y = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver.restore(sess, '../data/tf_save/trained_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1s of video. Time Elapsed 8.324521780014038s\n",
      "Processed 2s of video. Time Elapsed 9.013097286224365s\n",
      "Processed 3s of video. Time Elapsed 9.811070919036865s\n",
      "Processed 4s of video. Time Elapsed 9.051012754440308s\n",
      "Processed 5s of video. Time Elapsed 8.755149126052856s\n",
      "Processed 6s of video. Time Elapsed 8.846197128295898s\n",
      "Processed 7s of video. Time Elapsed 8.826620817184448s\n",
      "Processed 8s of video. Time Elapsed 8.854266881942749s\n",
      "Processed 9s of video. Time Elapsed 8.739827156066895s\n",
      "Processed 10s of video. Time Elapsed 9.119662284851074s\n",
      "Processed 11s of video. Time Elapsed 8.94359803199768s\n",
      "Processed 12s of video. Time Elapsed 8.793555974960327s\n",
      "Processed 13s of video. Time Elapsed 9.427101135253906s\n",
      "Processed 14s of video. Time Elapsed 9.555499792098999s\n",
      "Processed 15s of video. Time Elapsed 9.7904691696167s\n",
      "Processed 16s of video. Time Elapsed 9.375836849212646s\n",
      "Processed 17s of video. Time Elapsed 9.075401306152344s\n",
      "Processed 18s of video. Time Elapsed 9.319578886032104s\n",
      "Processed 19s of video. Time Elapsed 9.2120840549469s\n",
      "Processed 20s of video. Time Elapsed 8.992378234863281s\n",
      "Processed 21s of video. Time Elapsed 9.042136192321777s\n",
      "Processed 22s of video. Time Elapsed 9.049638986587524s\n",
      "Processed 23s of video. Time Elapsed 9.03917121887207s\n",
      "Processed 24s of video. Time Elapsed 9.127612113952637s\n",
      "Processed 25s of video. Time Elapsed 9.031850099563599s\n",
      "Processed 26s of video. Time Elapsed 9.156089782714844s\n",
      "Processed 27s of video. Time Elapsed 9.158721923828125s\n",
      "Processed 28s of video. Time Elapsed 9.219100952148438s\n",
      "Processed 29s of video. Time Elapsed 9.278542041778564s\n",
      "Processed 30s of video. Time Elapsed 9.190840005874634s\n",
      "Processed 31s of video. Time Elapsed 9.301922082901001s\n",
      "Processed 32s of video. Time Elapsed 9.245370149612427s\n",
      "Processed 33s of video. Time Elapsed 9.407969951629639s\n",
      "Processed 34s of video. Time Elapsed 9.430556058883667s\n",
      "Processed 35s of video. Time Elapsed 9.362281084060669s\n",
      "Processed 36s of video. Time Elapsed 9.43316102027893s\n",
      "Processed 37s of video. Time Elapsed 9.485130071640015s\n",
      "Processed 38s of video. Time Elapsed 9.54440712928772s\n",
      "Processed 39s of video. Time Elapsed 9.50773811340332s\n",
      "Processed 40s of video. Time Elapsed 9.612303256988525s\n",
      "Processed 41s of video. Time Elapsed 9.515400886535645s\n"
     ]
    }
   ],
   "source": [
    "MIN_CONTOUR_SIZE = 45\n",
    "WINDOW_SIZE = SIZE\n",
    "frame_count = 0\n",
    "\n",
    "video = cv2.VideoCapture('../data/videos/TandemRun.mp4')\n",
    "out_video = cv2.VideoWriter('../data/videos/out.mp4', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 30, (3840, 2160))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % 30 == 0:\n",
    "        print('Processed {}s of video. Time Elapsed {}s'.format(frame_count//30, time.time()-start_time))\n",
    "        start_time = time.time()\n",
    "        if frame_count // 30 > 40:\n",
    "            break\n",
    "      \n",
    "    cropped = frame[YMIN:YMAX, XMIN:XMAX]\n",
    "    grayed = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "    th = cv2.adaptiveThreshold(grayed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "    cxs, cys = find_centroids(th, MIN_CONTOUR_SIZE)\n",
    "    \n",
    "    masks = []\n",
    "    positions = []\n",
    "    \n",
    "    for cx, cy in zip(cxs, cys):\n",
    "        masked = get_masked_window(grayed, cx, cy, WINDOW_SIZE)\n",
    "        if masked is not None and masked.size == WINDOW_SIZE * WINDOW_SIZE:\n",
    "            masks.append(masked)\n",
    "            positions.append((cx, cy))\n",
    "    # Feed masked windows to trained model for prediction.\n",
    "    predictions = sess.run(tf.argmax(y, 1), feed_dict={x: masks})\n",
    "    for prediction, (cx, cy) in zip(predictions, positions):\n",
    "        if prediction == 1:\n",
    "            cv2.rectangle(frame, (cx+XMIN-15, cy+YMIN-15), (cx+XMIN+15, cy+YMIN+15), (0, 255, 0), 3)\n",
    "        elif prediction == 2:\n",
    "            cv2.rectangle(frame, (cx+XMIN-15, cy+YMIN-15), (cx+XMIN+15, cy+YMIN+15), (255, 0, 0), 3)\n",
    "       \n",
    "    out_video.write(frame)\n",
    "\n",
    "out_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
